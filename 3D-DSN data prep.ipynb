{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The code here transforms the data from Resampling.ipynb to a data format suitable for the 3D-DSN:\n",
    "https://www.sciencedirect.com/science/article/pii/S1361841517300725?via%3Dihub\n",
    "'''\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import os, sys\n",
    "#sys.path.insert(1, './Models/Resnet-3D')\n",
    "from resnet3d import Resnet3DBuilder\n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#if this is not here, the loaded notebook will not detect ensuing changes in imported numpy scripts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator for (ct,pet)->centre prediction models\n",
    "\n",
    "def zip_ct_pet(ct, pet):\n",
    "    ct = np.array(ct)[:,:,:,:,np.newaxis]\n",
    "    pet = np.array(pet)[:,:,:,:,np.newaxis]\n",
    "    return np.concatenate((ct, pet), axis=-1)\n",
    "\n",
    "def centre_predictor_generator(pet_files, ct_files, centres, shuffle=True, batch_size=4):\n",
    "    \n",
    "    while True:\n",
    "        nth_batch = 0\n",
    "        \n",
    "        if shuffle:\n",
    "            z = list(zip(pet_files, ct_files, centres))\n",
    "            random.shuffle(z)\n",
    "            pet_files, ct_files, centres = zip(*z)\n",
    "            \n",
    "        pet_batch = []\n",
    "        ct_batch = []\n",
    "        centre_batch = []\n",
    "        \n",
    "        for i in range(len(pet_files)):\n",
    "                \n",
    "            ct_batch.append(np.load(ct_files[i]))\n",
    "            pet_batch.append(np.load(pet_files[i]))\n",
    "            centre_batch.append(centres[i])\n",
    "            \n",
    "            if len(pet_batch) == batch_size:\n",
    "                yield zip_ct_pet(ct_batch, pet_batch), np.array(centre_batch)\n",
    "                \n",
    "                pet_batch.clear()\n",
    "                ct_batch.clear()\n",
    "                centre_batch.clear()\n",
    " \n",
    "        if len(ct_batch) > 0:\n",
    "            yield zip_ct_pet(ct_batch, pet_batch), np.array(centre_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jzhe0882/numpydata/PET/HN-HGJ-052.npy /home/jzhe0882/numpydata/CT/HN-HGJ-052.npy [61 40 50] /home/jzhe0882/numpydata/Mask/HN-HGJ-052.npy\n",
      "/home/jzhe0882/numpydata/PET/HN-CHUM-028.npy /home/jzhe0882/numpydata/CT/HN-CHUM-028.npy [65 48 54] /home/jzhe0882/numpydata/Mask/HN-CHUM-028.npy\n"
     ]
    }
   ],
   "source": [
    "#load training data from disk\n",
    "pet_files = []\n",
    "ct_files = []\n",
    "centre_files = []\n",
    "mask_files = []\n",
    "\n",
    "for root, dirs, files in os.walk('/home/jzhe0882/numpydata/PET'):\n",
    "    for name in files:\n",
    "        file_path = os.path.join(root, name)\n",
    "        pet_files.append(file_path)\n",
    "\n",
    "for root, dirs, files in os.walk('/home/jzhe0882/numpydata/CT'):\n",
    "    for name in files:\n",
    "        file_path = os.path.join(root, name)\n",
    "        ct_files.append(file_path)\n",
    "\n",
    "for root, dirs, files in os.walk('/home/jzhe0882/numpydata/MaskCentres'):\n",
    "    for name in files:\n",
    "        file_path = os.path.join(root, name)\n",
    "        centre_files.append(file_path)\n",
    "        \n",
    "for root, dirs, files in os.walk('/home/jzhe0882/numpydata/Mask'):\n",
    "    for name in files:\n",
    "        file_path = os.path.join(root, name)\n",
    "        mask_files.append(file_path)\n",
    "\n",
    "pet_files = sorted(pet_files)\n",
    "ct_files = sorted(ct_files)\n",
    "centre_files = sorted(centre_files)\n",
    "centres = [np.load(c) for c in centre_files] #can load all of these into memory (other volumes are too large)\n",
    "mask_files = sorted(mask_files)\n",
    "\n",
    "#Inputs are PET/CT data, outputs are centres or masks\n",
    "X_train, X_test, y_train, y_test = train_test_split(list(zip(pet_files, ct_files)), \n",
    "                                                    list(zip(centres, mask_files)), \n",
    "                                                    test_size=0.33, shuffle=True, random_state=9)\n",
    "\n",
    "pet_train, ct_train = zip(*X_train)\n",
    "pet_test, ct_test = zip(*X_test)\n",
    "centre_train, mask_train = zip(*y_train)\n",
    "centre_test, mask_test = zip(*y_test)\n",
    "\n",
    "print(pet_train[0], ct_train[0], centre_train[0], mask_train[0])\n",
    "print(pet_test[0], ct_test[0], centre_test[0], mask_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 batches of 4 samples taken over 65 total samples\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "#test to see if generator works\n",
    "\n",
    "batch_size = 4\n",
    "test_generator = centre_predictor_generator(pet_test, ct_test, centre_test, batch_size=batch_size, shuffle=False)\n",
    "print('{} batches of {} samples taken over {} total samples'.format(math.ceil(len(ct_test)/batch_size), batch_size, len(ct_test)))\n",
    "\n",
    "for i in range(math.ceil(len(ct_test)/batch_size)):\n",
    "    ctpet, centre = next(test_generator)\n",
    "    print(i, ctpet.shape, centre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "330/330 [==============================] - 73s 221ms/step - loss: 614.8951 - val_loss: 126.1881\n",
      "Epoch 2/10\n",
      "330/330 [==============================] - 63s 191ms/step - loss: 41.8186 - val_loss: 65.1765\n",
      "Epoch 3/10\n",
      "330/330 [==============================] - 63s 191ms/step - loss: 26.6939 - val_loss: 36.1474\n",
      "Epoch 4/10\n",
      "330/330 [==============================] - 63s 192ms/step - loss: 19.4052 - val_loss: 34.9923\n",
      "Epoch 5/10\n",
      "330/330 [==============================] - 63s 192ms/step - loss: 16.0235 - val_loss: 30.4433\n",
      "Epoch 6/10\n",
      "330/330 [==============================] - 63s 192ms/step - loss: 12.0020 - val_loss: 33.3358\n",
      "Epoch 7/10\n",
      "330/330 [==============================] - 63s 192ms/step - loss: 10.8811 - val_loss: 32.0355\n",
      "Epoch 8/10\n",
      "330/330 [==============================] - 63s 192ms/step - loss: 9.3130 - val_loss: 27.0790\n",
      "Epoch 9/10\n",
      "330/330 [==============================] - 63s 191ms/step - loss: 7.3810 - val_loss: 29.8361\n",
      "Epoch 10/10\n",
      "330/330 [==============================] - 62s 189ms/step - loss: 6.9854 - val_loss: 26.4268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb6c610ba8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "cycles_per_epoch = 10 # how many times the entire training set should be cycled over for each epoch\n",
    "total_cycles = 100 # how many times the entire training set should be cycled in total\n",
    "input_shape = (128, 128, 96, 2)\n",
    "train_generator = centre_predictor_generator(pet_train, ct_train, centre_train, batch_size=batch_size)\n",
    "validation_generator = centre_predictor_generator(pet_test, ct_test, centre_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "detection_model = Resnet3DBuilder.build_resnet_18(input_shape, 3)\n",
    "detection_model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error')\n",
    "detection_model.fit_generator(train_generator, validation_data=validation_generator, validation_steps=math.ceil(len(ct_test)/batch_size),\n",
    "                   steps_per_epoch=cycles_per_epoch*math.ceil(len(ct_train)/batch_size), epochs=math.ceil(total_cycles/cycles_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model.save('Models/keras models/detection_model_resnet18.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "detection_model = load_model('Models/keras models/detection_model_resnet18.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generates a bounding box around the centre\n",
    "def get_bounding_box(source_volume, centre, maximal_extents):\n",
    "    maxima = centre + maximal_extents\n",
    "    minima = centre - maximal_extents\n",
    "    \n",
    "    #keep bounding box dimensions within the mask dimensions\n",
    "    maxima = np.minimum(maxima, np.array(source_volume.shape)).astype(int)\n",
    "    minima = np.maximum(minima, [0,0,0]).astype(int) \n",
    "        \n",
    "    bounding_box_values = source_volume[minima[0]:maxima[0],\n",
    "                              minima[1]:maxima[1],\n",
    "                              minima[2]:maxima[2]]\n",
    "    \n",
    "    relative_centre = maximal_extents\n",
    "    relative_maxima = (relative_centre + maxima - centre).astype(int)\n",
    "    relative_minima = (relative_centre + minima - centre).astype(int)\n",
    "    \n",
    "    bounding_box = np.zeros(2 * maximal_extents)\n",
    "    \n",
    "    bounding_box[relative_minima[0]:relative_maxima[0],\n",
    "                relative_minima[1]:relative_maxima[1],\n",
    "                relative_minima[2]:relative_maxima[2]] = bounding_box_values\n",
    "    \n",
    "    #print(relative_minima, relative_maxima)\n",
    "    \n",
    "    return bounding_box\n",
    "\n",
    "#translates the bounding box so that its values have a new reference centre\n",
    "def align_bounding_box(bounding_box, box_centre, target_centre):\n",
    "    displacement = (target_centre - box_centre).astype(int)\n",
    "                      \n",
    "    for i in range(len(displacement)): #if true, the centres are too far apart for original bounding box values to be seen\n",
    "        if displacement[i] >= bounding_box.shape[i]:\n",
    "            return np.zeros(bounding_box.shape[i])\n",
    "    \n",
    "    new_box = np.roll(bounding_box, displacement, axis=(0,1,2))\n",
    "                      \n",
    "    #boxes shifted backward have a trail of zeroes at the end of the array\n",
    "    #boxes shifted forward have a trail of zeroes at the beginning of the array\n",
    "    if displacement[0] < 0:\n",
    "        new_box[displacement[0]:, :, :] = 0\n",
    "    else:\n",
    "        new_box[:displacement[0], :, :] = 0\n",
    "                      \n",
    "    if displacement[1] < 0:\n",
    "        new_box[:, displacement[1]:, :] = 0\n",
    "    else:\n",
    "        new_box[:, :displacement[1], :] = 0\n",
    "    \n",
    "    if displacement[2] < 0:\n",
    "        new_box[:, :, displacement[2]:] = 0\n",
    "    else:\n",
    "        new_box[:, :, :displacement[2]] = 0\n",
    "        \n",
    "    return new_box\n",
    "\n",
    "#values derived from NumpyAnalysis.ipynb\n",
    "maximal_extents = np.array([22, 13, 28], dtype=int)\n",
    "\n",
    "#generator for (ct bounding box, pet bounding_box)-> mask bounding box prediction models\n",
    "def mask_bounding_box_predictor_generator(pet_files, ct_files, mask_files, centres, shuffle=True, batch_size=4):\n",
    "    \n",
    "    while True:\n",
    "        if shuffle:\n",
    "            z = list(zip(pet_files, ct_files, centres, mask_files))\n",
    "            random.shuffle(z)\n",
    "            pet_files, ct_files, centres, mask_files = zip(*z)\n",
    "            \n",
    "        pet_batch = []\n",
    "        ct_batch = []\n",
    "        mask_batch = []\n",
    "        \n",
    "        for i in range(len(pet_files)):\n",
    "             \n",
    "            ct_batch.append(get_bounding_box(np.load(ct_files[i]), centres[i], maximal_extents))\n",
    "            pet_batch.append(get_bounding_box(np.load(pet_files[i]), centres[i], maximal_extents))\n",
    "            mask_batch.append(get_bounding_box(np.load(mask_files[i]), centres[i], maximal_extents))\n",
    "            \n",
    "            if len(pet_batch) == batch_size:\n",
    "                yield zip_ct_pet(ct_batch, pet_batch), np.array(mask_batch)\n",
    "                \n",
    "                pet_batch.clear()\n",
    "                ct_batch.clear()\n",
    "                mask_batch.clear()\n",
    "                \n",
    "        yield zip_ct_pet(ct_batch, pet_batch), np.array(mask_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2  3  4  5]\n",
      "  [ 6  7  8  9 10]\n",
      "  [11 12 13 14 15]]\n",
      "\n",
      " [[16 17 18 19 20]\n",
      "  [21 22 23 24 25]\n",
      "  [26 27 28 29 30]]]\n",
      "[[[0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 1.]]]\n",
      "1\n",
      "[[[0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "test = np.arange(1,31).reshape(2,3,5)\n",
    "print(test)\n",
    "centre = [0,0,0]\n",
    "print(get_bounding_box(test, np.array(centre), np.array([1,1,1])))\n",
    "print(test[centre[0], centre[1], centre[2]])\n",
    "test = align_bounding_box(test, np.array([0,0,0]), np.array([-2,1,1]))\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def dice_eval(pred_mask, true_mask):\n",
    "    pred_mask = pred_mask.flatten()\n",
    "    true_mask = true_mask.flatten()\n",
    "    ret = distance.dice(pred_mask, true_mask)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice accuracy 0.09947735814980829\n",
      "26.426832785973183\n",
      "[23.34948369 11.0483397  36.41964497]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "    \n",
    "test_generator = centre_predictor_generator(pet_test, ct_test, centre_test, batch_size=batch_size, shuffle=False)    \n",
    "detected_centres = detection_model.predict_generator(test_generator, steps=math.ceil(len(ct_test)/batch_size))\n",
    "    \n",
    "dice_sum = 0\n",
    "for i in range(len(detected_centres)):\n",
    "    mask = np.load(mask_test[i])\n",
    "    \n",
    "    pred_mask = get_bounding_box(mask, np.rint(detected_centres[i]).astype(int), maximal_extents)\n",
    "    pred_mask = align_bounding_box(pred_mask, detected_centres[i], centre_test[i])\n",
    "    \n",
    "    true_mask = get_bounding_box(mask, centre_test[i].astype(int), maximal_extents)\n",
    "    \n",
    "    dice_index = dice_eval(pred_mask, true_mask)\n",
    "    \n",
    "    dice_sum += dice_index\n",
    "    \n",
    "print('dice accuracy', 1 - dice_sum / len(detected_centres))\n",
    "    \n",
    "print(detection_model.evaluate_generator(validation_generator, steps=math.ceil(len(ct_test)/batch_size)))\n",
    "#print(detected_centres.shape)\n",
    "print(mean_squared_error(detected_centres, centre_test, multioutput='raw_values'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 44, 26, 56, 2) (100, 44, 26, 56)\n",
      "(29, 44, 26, 56, 2) (29, 44, 26, 56)\n",
      "(100, 44, 26, 56, 2) (100, 44, 26, 56)\n",
      "(29, 44, 26, 56, 2) (29, 44, 26, 56)\n"
     ]
    }
   ],
   "source": [
    "generator2 = mask_bounding_box_predictor_generator(ct_train, pet_train, mask_train, centre_train, batch_size=100)\n",
    "\n",
    "for i in range(4):\n",
    "    ctpet, mask = next(generator2)\n",
    "    print(ctpet.shape,mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "33/33 [==============================] - 10s 318ms/step - loss: 6.9243 - val_loss: 29.1363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc7e626f358>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_model.fit_generator(train_generator, validation_data=validation_generator, validation_steps=math.ceil(len(ct_test)/batch_size),\n",
    "                   steps_per_epoch=math.ceil(len(ct_train)/batch_size), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]]\n",
      "[[14 10 11 12 13]\n",
      " [19 15 16 17 18]\n",
      " [ 4  0  1  2  3]\n",
      " [ 9  5  6  7  8]]\n",
      "[[10 11 12 13]\n",
      " [15 16 17 18]\n",
      " [ 0  1  2  3]\n",
      " [ 5  6  7  8]]\n"
     ]
    }
   ],
   "source": [
    "def blyat(arr):\n",
    "    return np.roll(arr, [2,1], [0,1])\n",
    "    \n",
    "test = np.arange(20).reshape(4,5)\n",
    "print(test)\n",
    "test=blyat(test)\n",
    "print(test)\n",
    "print(test[-0:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
